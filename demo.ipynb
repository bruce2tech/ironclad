{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ironclad Face Recognition Demo\n",
    "\n",
    "This notebook demonstrates the core functionality of the Ironclad face recognition system.\n",
    "\n",
    "## Features Demonstrated:\n",
    "1. Face embedding extraction using VGGFace2\n",
    "2. Building a searchable index with FAISS HNSW\n",
    "3. Face identification and similarity search\n",
    "4. Performance comparison between different search methods\n",
    "\n",
    "## Setup\n",
    "Make sure you have all dependencies installed:\n",
    "```bash\n",
    "pip install torch torchvision pillow numpy faiss-cpu flask\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Import ironclad modules\n",
    "from ironclad.modules.extraction.embedding import Embedding\n",
    "from ironclad.modules.extraction.preprocessing import Preprocessing\n",
    "from ironclad.modules.retrieval.index.hnsw import FaissHNSW\n",
    "from ironclad.modules.retrieval.index.bruteforce import BruteForce\n",
    "from ironclad.modules.retrieval.search import FaissSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "GALLERY_DIR = 'demo_data/gallery'\n",
    "QUERY_DIR = 'demo_data/queries'\n",
    "MODEL = 'vggface2'  # Options: 'vggface2', 'facenet'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessing and embedding model\n",
    "preprocessor = Preprocessing()\n",
    "embedding_model = Embedding(pretrained=MODEL, device=DEVICE)\n",
    "\n",
    "print(\"Models initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Gallery Images\n",
    "\n",
    "Load and process all images from the gallery to build our face database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gallery_images(gallery_path):\n",
    "    \"\"\"Load all images from gallery directory.\"\"\"\n",
    "    gallery_images = []\n",
    "    gallery_labels = []\n",
    "    \n",
    "    for person_name in os.listdir(gallery_path):\n",
    "        person_dir = os.path.join(gallery_path, person_name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_file in os.listdir(person_dir):\n",
    "            if img_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(person_dir, img_file)\n",
    "                gallery_images.append(img_path)\n",
    "                gallery_labels.append(person_name)\n",
    "    \n",
    "    return gallery_images, gallery_labels\n",
    "\n",
    "gallery_images, gallery_labels = load_gallery_images(GALLERY_DIR)\n",
    "print(f\"Loaded {len(gallery_images)} images from {len(set(gallery_labels))} people\")\n",
    "print(f\"People in gallery: {sorted(set(gallery_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Gallery Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few sample images from the gallery\n",
    "fig, axes = plt.subplots(1, min(5, len(gallery_images)), figsize=(15, 3))\n",
    "if len(gallery_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (img_path, label) in enumerate(zip(gallery_images[:5], gallery_labels[:5])):\n",
    "    img = Image.open(img_path)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(label.replace('_', ' '))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Face Embeddings\n",
    "\n",
    "Generate embedding vectors for all gallery images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(image_paths, preprocessor, model):\n",
    "    \"\"\"Extract embeddings for a list of images.\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        # Load and preprocess image\n",
    "        img = Image.open(img_path)\n",
    "        processed_img = preprocessor(img)\n",
    "        \n",
    "        # Extract embedding\n",
    "        embedding = model(processed_img)\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    return np.array(embeddings)\n",
    "\n",
    "print(\"Extracting gallery embeddings...\")\n",
    "gallery_embeddings = extract_embeddings(gallery_images, preprocessor, embedding_model)\n",
    "print(f\"Gallery embeddings shape: {gallery_embeddings.shape}\")\n",
    "print(f\"Embedding dimension: {gallery_embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build Search Indices\n",
    "\n",
    "Create both HNSW (fast approximate) and Brute-Force (exact) search indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build HNSW index for fast approximate nearest neighbor search\n",
    "print(\"Building HNSW index...\")\n",
    "hnsw_index = FaissHNSW(similarity_measure='cosine', m=16, ef_construction=200)\n",
    "hnsw_index.build(gallery_embeddings)\n",
    "print(\"HNSW index built!\")\n",
    "\n",
    "# Build brute-force index for exact search (comparison baseline)\n",
    "print(\"\\nBuilding Brute-Force index...\")\n",
    "bf_index = BruteForce(similarity_measure='cosine')\n",
    "bf_index.build(gallery_embeddings)\n",
    "print(\"Brute-Force index built!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Face Identification Demo\n",
    "\n",
    "Test face identification with query images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_face(query_image_path, index, k=3):\n",
    "    \"\"\"Identify a face and return top-k matches.\"\"\"\n",
    "    # Load and preprocess query image\n",
    "    img = Image.open(query_image_path)\n",
    "    processed_img = preprocessor(img)\n",
    "    \n",
    "    # Extract embedding\n",
    "    query_embedding = embedding_model(processed_img)\n",
    "    \n",
    "    # Search for similar faces\n",
    "    distances, indices = index.search(query_embedding.reshape(1, -1), k=k)\n",
    "    \n",
    "    # Get top-k matches\n",
    "    results = []\n",
    "    for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "        results.append({\n",
    "            'rank': i + 1,\n",
    "            'name': gallery_labels[idx],\n",
    "            'image': gallery_images[idx],\n",
    "            'distance': dist\n",
    "        })\n",
    "    \n",
    "    return img, results\n",
    "\n",
    "# Get a query image\n",
    "query_images = []\n",
    "for person_name in os.listdir(QUERY_DIR):\n",
    "    person_dir = os.path.join(QUERY_DIR, person_name)\n",
    "    if os.path.isdir(person_dir):\n",
    "        for img_file in os.listdir(person_dir):\n",
    "            if img_file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                query_images.append(os.path.join(person_dir, img_file))\n",
    "\n",
    "if query_images:\n",
    "    query_path = query_images[0]\n",
    "    query_name = Path(query_path).parent.name\n",
    "    \n",
    "    print(f\"Query image: {query_name}\")\n",
    "    query_img, results = identify_face(query_path, hnsw_index, k=3)\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    # Show query image\n",
    "    axes[0].imshow(query_img)\n",
    "    axes[0].set_title(f'Query: {query_name.replace(\"_\", \" \")}', fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Show top-3 matches\n",
    "    for i, result in enumerate(results):\n",
    "        match_img = Image.open(result['image'])\n",
    "        axes[i+1].imshow(match_img)\n",
    "        axes[i+1].set_title(\n",
    "            f\"#{result['rank']}: {result['name'].replace('_', ' ')}\\nDist: {result['distance']:.3f}\",\n",
    "            fontsize=10\n",
    "        )\n",
    "        axes[i+1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop-3 Matches:\")\n",
    "    for result in results:\n",
    "        print(f\"  {result['rank']}. {result['name']} (distance: {result['distance']:.4f})\")\n",
    "else:\n",
    "    print(\"No query images found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Comparison: HNSW vs Brute-Force\n",
    "\n",
    "Compare speed and accuracy between approximate (HNSW) and exact (Brute-Force) search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if query_images:\n",
    "    # Prepare query embedding\n",
    "    query_path = query_images[0]\n",
    "    img = Image.open(query_path)\n",
    "    processed_img = preprocessor(img)\n",
    "    query_embedding = embedding_model(processed_img).reshape(1, -1)\n",
    "    \n",
    "    # Benchmark HNSW\n",
    "    start = time.time()\n",
    "    hnsw_dists, hnsw_indices = hnsw_index.search(query_embedding, k=5)\n",
    "    hnsw_time = time.time() - start\n",
    "    \n",
    "    # Benchmark Brute-Force\n",
    "    start = time.time()\n",
    "    bf_dists, bf_indices = bf_index.search(query_embedding, k=5)\n",
    "    bf_time = time.time() - start\n",
    "    \n",
    "    print(\"Performance Comparison:\")\n",
    "    print(f\"  HNSW Search Time: {hnsw_time*1000:.2f} ms\")\n",
    "    print(f\"  Brute-Force Search Time: {bf_time*1000:.2f} ms\")\n",
    "    print(f\"  Speedup: {bf_time/hnsw_time:.2f}x\")\n",
    "    \n",
    "    # Check if results match (they should be very similar)\n",
    "    matching_results = np.sum(hnsw_indices[0] == bf_indices[0])\n",
    "    print(f\"\\n  Top-5 Results Match: {matching_results}/5\")\n",
    "    print(f\"  HNSW Top-1: {gallery_labels[hnsw_indices[0][0]]}\")\n",
    "    print(f\"  BF Top-1: {gallery_labels[bf_indices[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Embedding Space Visualization\n",
    "\n",
    "Visualize the embedding space using dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce embeddings to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(gallery_embeddings)\n",
    "\n",
    "# Create color map for different people\n",
    "unique_labels = sorted(set(gallery_labels))\n",
    "label_to_color = {label: i for i, label in enumerate(unique_labels)}\n",
    "colors = [label_to_color[label] for label in gallery_labels]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                     c=colors, cmap='tab10', s=100, alpha=0.6)\n",
    "plt.title('Face Embedding Space (PCA Projection)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "\n",
    "# Add legend\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                     markerfacecolor=scatter.cmap(scatter.norm(i)), \n",
    "                     markersize=8, label=label.replace('_', ' ')) \n",
    "          for i, label in enumerate(unique_labels)]\n",
    "plt.legend(handles=handles, loc='best')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Explained variance: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demo showcased:\n",
    "1. ✅ Face embedding extraction using state-of-the-art models\n",
    "2. ✅ Fast similarity search with FAISS HNSW\n",
    "3. ✅ Face identification with top-k matching\n",
    "4. ✅ Performance comparison between search methods\n",
    "5. ✅ Embedding space visualization\n",
    "\n",
    "### Next Steps\n",
    "- Explore the benchmarking scripts in the repository\n",
    "- Try different embedding models (VGGFace2, FaceNet)\n",
    "- Test with larger datasets\n",
    "- Run the Flask API server for production use\n",
    "\n",
    "### Key Takeaways\n",
    "- **HNSW provides significant speedup** over brute-force search with minimal accuracy loss\n",
    "- **Face embeddings cluster by identity** in the high-dimensional space\n",
    "- **System is modular and extensible** for different models and indexing methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
